{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop better semantic similarity evaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simon/master_project/software/venv_koenigsi/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import time\n",
    "from bert_score import BERTScorer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simon/master_project/software/venv_koenigsi/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken = 7.904077768325806\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.1648]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def semantic_similarity(model, sentence1, sentence2):\n",
    "    # multi-qa-MiniLM-L6-cos-v1, cheap model for dev\n",
    "    # all-mpnet-base-v2 , more performant model, but slower\n",
    "    sentence1_vec = model.encode([sentence1])\n",
    "\n",
    "    sentence2_vec = model.encode([sentence2])\n",
    "\n",
    "    similarity_score = model.similarity(\n",
    "        sentence1_vec, sentence2_vec\n",
    "    )  # Default is cosine simi\n",
    "    # print(f\"\\n Similarity Score = {similarity_score} \")\n",
    "\n",
    "    return similarity_score\n",
    "\n",
    "\n",
    "sentence = \"Yes, Lincoln was eventually chosen as the Republican candidate for the 1860 election.\"\n",
    "reference = \"Yes\"\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "start = time.time()\n",
    "for i in range(100):\n",
    "    score = semantic_similarity(model, sentence, reference)\n",
    "end = time.time()\n",
    "print(f\"Time taken = {end-start}\")\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improved: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore Precision: 0.9955, Recall: 0.9955, F1: 0.9955\n",
      "BERTScore Precision: 0.9955, Recall: 0.9955, F1: 0.9955\n",
      "Time taken = 0.2005908489227295\n"
     ]
    }
   ],
   "source": [
    "def semantic_similarity(scorer, sentence, reference):\n",
    "    # Example texts\n",
    "    # BERTScore calculation\n",
    "    P, R, F1 = scorer.score([sentence], [reference])\n",
    "    # print(f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")\n",
    "    return P,R,F1\n",
    "\n",
    "\n",
    "\n",
    "sentence = \"no\"\n",
    "reference = \"yes\"\n",
    "scorer = BERTScorer(model_type='roberta-large', lang='en')\n",
    "start = time.time()\n",
    "\n",
    "p,r,f1= semantic_similarity(scorer,reference,sentence)\n",
    "print(f\"BERTScore Precision: {p.mean():.4f}, Recall: {r.mean():.4f}, F1: {f1.mean():.4f}\")\n",
    "p,r,f1 = semantic_similarity(scorer, sentence,reference)\n",
    "print(f\"BERTScore Precision: {p.mean():.4f}, Recall: {r.mean():.4f}, F1: {f1.mean():.4f}\")\n",
    "end = time.time()\n",
    "print(f\"Time taken = {end-start}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_koenigsi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
