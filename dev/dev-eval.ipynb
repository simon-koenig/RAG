{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to develop rag evaluation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define API ENDPOINTS \n",
    "LLM_URL=\"http://10.103.251.104:8040/v1\"\n",
    "LLM_NAME=\"mixtral\"\n",
    "MARQO_URL=\"http://10.103.251.104:8882\"\n",
    "# Old Marqo endpoint; version 1.5\n",
    "# MARQO_URL=\"http://10.103.251.100:8882\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import marqo\n",
    "import re\n",
    "import os\n",
    "from langchain.text_splitter import (\n",
    "    CharacterTextSplitter,  # need to install langchain\n",
    "    NLTKTextSplitter,\n",
    "    RecursiveCharacterTextSplitter,\n",
    ")\n",
    "from datasets import load_dataset\n",
    "import pprint\n",
    "import time\n",
    "import random\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function definitions\n",
    "\n",
    "def token_estimate(text):  # OpenAI suggest a token consists of 3/4 words\n",
    "    return len(re.findall(r\"\\w+\", text)) * 4 / 3\n",
    "\n",
    "\n",
    "def get_marqo_client(murl):\n",
    "    # Create a connection with the marqo instance\n",
    "    return marqo.Client(url=murl)\n",
    "\n",
    "\n",
    "def createIndex(mq, indexName, settings):\n",
    "    try:\n",
    "        split_method = settings[\"split_method\"]\n",
    "        distance_metric = settings[\"distance_metric\"]\n",
    "        model = settings[\"model\"]\n",
    "\n",
    "    except:\n",
    "        print(\n",
    "            f\"Settings could not be parsed to create a new index with name: {indexName}\"\n",
    "        )\n",
    "\n",
    "    indexName = indexName.lower()\n",
    "    if indexName in mq.get_indexes():\n",
    "        print(f\"Index already exists: {indexName} \")\n",
    "    else:\n",
    "        index_settings = {\n",
    "                \"model\": model,\n",
    "                \"normalizeEmbeddings\": True,\n",
    "                \"textPreprocessing\": {\n",
    "                    \"splitLength\": 2,\n",
    "                    \"splitOverlap\": 0,\n",
    "                    \"splitMethod\": split_method,\n",
    "                },\n",
    "                \"annParameters\": {\n",
    "                    \"spaceType\": distance_metric,\n",
    "                    # Tinker with this. Try increasing efConstruction along with m for better recall\n",
    "                    # https://www.pinecone.io/learn/series/faiss/hnsw/\n",
    "                    \"parameters\": {\"efConstruction\": 512, \"m\": 16},\n",
    "                },\n",
    "        }\n",
    "        try:\n",
    "            mq.create_index(indexName, settings_dict=index_settings)\n",
    "            #mq.create_index(indexName,  model='flax-sentence-embeddings/all_datasets_v4_mpnet-base')\n",
    "            print(\"New index created: \" + indexName)\n",
    "        except:\n",
    "            print(\n",
    "                \"Failed to created new index: \" + indexName + \" - check marqo endpoint!\"\n",
    "            )\n",
    "\n",
    "\n",
    "def deleteIndex(mq, indexName):\n",
    "    # Delete index by indexName\n",
    "    try:\n",
    "        # now remove the marqo index\n",
    "        mq.delete_index(indexName)\n",
    "        # now remove the files -- For now, no need to delete the files locally.\n",
    "        # output_directory = os.path.join(OUTPUT_DIRECTORY, indexName)\n",
    "        # if os.path.exists(output_directory):\n",
    "        #     shutil.rmtree(output_directory)\n",
    "        # else:\n",
    "        #     print(\"No associated file directories found and hence none deleted.\")\n",
    "\n",
    "        print(f\" Sucessfuylly deleted Index: {indexName}\")\n",
    "    except:\n",
    "        print(\"Unable to delete: \" + indexName)\n",
    "\n",
    "\n",
    "def printIndexes(marqoClient):\n",
    "    for index in marqoClient.get_indexes()[\"results\"]:\n",
    "        print(index)\n",
    "\n",
    "\n",
    "def upload_mini_wiki(corpus, chunking_params):\n",
    "    # Upload a mini wiki corpus to the marqo instance\n",
    "    # The corpus is a dictionary with two keys. Passages and id. \n",
    "    # Passage is a list of strings \n",
    "    # Id is a list of ints.\n",
    "    # Open the PDF file\n",
    "   \n",
    "        for passage, iD in zip(corpus[\"passage\"], corpus[\"id\"]):\n",
    "\n",
    "            tokens = token_estimate(passage)\n",
    "            # TODO: Add a check and compare current file by id and timestamp\n",
    "            # If file is already in the index, check if it has been modified\n",
    "            # If the file has been modified, update the file in the index\n",
    "            try:\n",
    "                marqoClient.index(INDEX_NAME).add_documents(\n",
    "                    [\n",
    "                        {\n",
    "                            \"text\": passage,\n",
    "                            \"tokens\": tokens,\n",
    "                            \"id\": iD,\n",
    "                        }\n",
    "                    ],\n",
    "                    # Arguments in tensor_fields will have vectors generated for them. For best recall and performance, minimise the number of arguments in tensor_fields.\n",
    "                    tensor_fields=[\"text\"],\n",
    "                )\n",
    "            except:\n",
    "                print(f\"Ingest error for passage with id: {iD}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to created new index: mini_wiki_index - check marqo endpoint!\n",
      "{'indexName': 'mini_wiki_index'}\n",
      "{'indexName': 'ait-qm'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200\n",
      "Time taken to upload 3200 passages: 238.87357354164124 seconds\n",
      "{'numberOfDocuments': 3205, 'numberOfVectors': 6312, 'backend': {'memoryUsedPercentage': 0.066052599, 'storageUsedPercentage': 48.54578915951}}\n"
     ]
    }
   ],
   "source": [
    "# Set Index Settings, docs: https://docs.marqo.ai/2.5/API-Reference/Indexes/create_index/\n",
    "\n",
    "# Open marqo with index name, if index not found create new index with the name\n",
    "marqoClient = get_marqo_client(MARQO_URL)\n",
    "INDEX_NAME = \"mini_wiki_index\"\n",
    "index_params = {\n",
    "    \"split_method\": \"sentence\",\n",
    "    \"distance_metric\": \"prenormalized-angular\",\n",
    "    \"model\": \"hf/all_datasets_v4_MiniLM-L6\",\n",
    "    #\"model\" : 'flax-sentence-embeddings/all_datasets_v4_mpnet-base',\n",
    "}\n",
    "\n",
    "chunking_params = {\n",
    "    \"chunk_size\": 1024,\n",
    "    \"chunk_overlap\": 128,\n",
    "    \"chunk_method\": \"recursive\",\n",
    "}\n",
    "\n",
    "# Test createIndex and deleteIndex\n",
    "createIndex(marqoClient, INDEX_NAME, index_params)\n",
    "printIndexes(marqoClient)\n",
    "\n",
    "\n",
    "# Index chunks of data\n",
    "# Get the mini wiki corpus\n",
    "mini_wiki_corpus = load_dataset(\"rag-datasets/mini_wikipedia\", \"text-corpus\")\n",
    "passages = mini_wiki_corpus[\"passages\"] # Load the first 5 passages\n",
    "print(len(passages))\n",
    "upload_start = time.time()\n",
    "upload_mini_wiki(passages, chunking_params)\n",
    "upload_end = time.time()\n",
    "print(f\"Time taken to upload {len(passages)} passages: {upload_end - upload_start} seconds\")\n",
    "# Check if index contains data\n",
    "print(marqoClient.index(INDEX_NAME).get_stats())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now we have the documents indexed. Now retrieve passages based on a query. \n",
    "Indexing 3200 short passages takes ~ 4minutes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': ['Was Abraham Lincoln the sixteenth President of the United States?', 'Did Lincoln sign the National Banking Act of 1863?', 'Did his mother die of pneumonia?', \"How many long was Lincoln's formal education?\", 'When did Lincoln begin his political career?'], 'answer': ['yes', 'yes', 'no', '18 months', '1832'], 'id': [0, 2, 4, 6, 8]}\n",
      "['Was Abraham Lincoln the sixteenth President of the United States?', 'Did Lincoln sign the National Banking Act of 1863?', 'Did his mother die of pneumonia?', \"How many long was Lincoln's formal education?\", 'When did Lincoln begin his political career?']\n",
      "['yes', 'yes', 'no', '18 months', '1832']\n"
     ]
    }
   ],
   "source": [
    "# Get question - answer - (passages) dataset\n",
    "mini_wiki_qa = load_dataset(\"rag-datasets/mini_wikipedia\", \"question-answer\")\n",
    "mini_wiki_qa = mini_wiki_qa[\"test\"][0:5] # Load the first 5 qestion-answer-id triples\n",
    "print(mini_wiki_qa)\n",
    "questions = mini_wiki_qa[\"question\"]\n",
    "answers = mini_wiki_qa[\"answer\"]\n",
    "print(questions)\n",
    "print(answers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9852319488424731\n",
      "['Young Abraham Lincoln',\n",
      " 'Abraham Lincoln (February 12, 1809 Ã¢\\x80\\x93 April 15, 1865) was the '\n",
      " 'sixteenth President of the United States, serving from March 4, 1861 until '\n",
      " 'his assassination. As an outspoken opponent of the expansion of slavery in '\n",
      " 'the United States, \"[I]n his short autobiography written for the 1860 '\n",
      " 'presidential campaign, Lincoln would describe his protest in the Illinois '\n",
      " \"legislature as one that 'briefly defined his position on the slavery \"\n",
      " 'question, and so far as it goes, it was then the same that it is now.\" This '\n",
      " 'was in reference to the anti-expansion sentiments he had then expressed. '\n",
      " 'Doris Kearns Goodwin, Team of Rivals: The Political Genius of Abraham '\n",
      " 'Lincoln (2005) p. 91.  Holzer pg. 232.  Writing of the Cooper Union  speech, '\n",
      " 'Holzer notes, \"Cooper Union proved a unique confluence of political culture, '\n",
      " 'rhetorical opportunity, technological innovation, and human genius, and it '\n",
      " 'brought Abraham Lincoln to the center stage of American politics at '\n",
      " 'precisely the right time and place, and with precisely the right message: '\n",
      " 'that slavery was wrong, and ought to be confined to the areas where it '\n",
      " 'already existed, and placed on the \\'course of ultimate extinction... .\\'\"  '\n",
      " 'Lincoln won the Republican Party nomination in 1860 and was elected '\n",
      " 'president later that year. During his term, he helped preserve the United '\n",
      " 'States by leading the defeat of the secessionist Confederate States of '\n",
      " 'America in the American Civil War. He introduced measures that resulted in '\n",
      " 'the abolition of slavery, issuing his Emancipation Proclamation in 1863 and '\n",
      " 'promoting the passage of the Thirteenth Amendment to the Constitution in '\n",
      " '1865.']\n"
     ]
    }
   ],
   "source": [
    "# Send Questions to index to retrieve data from vector db\n",
    "for question in questions[:1]:\n",
    "    response = marqoClient.index(INDEX_NAME).search(\n",
    "        q=question, \n",
    "        limit=2,\n",
    "        attributes_to_retrieve=[\"text\"],\n",
    "    )\n",
    "    # pprint.pprint(response)\n",
    "    \n",
    "\n",
    "# 1. Analyse Search Results - CONTEXT RELEVANCE\n",
    "def evaluate_context_relevance(response):\n",
    "    return random.random()\n",
    "\n",
    "context_score = evaluate_context_relevance(response)\n",
    "print(context_score)\n",
    "\n",
    "# Get retrieved text. \n",
    "contexts = [response[\"hits\"][i][\"text\"] for i in range(len(response[\"hits\"]))]\n",
    "pprint.pprint(contexts)\n",
    "background = \"\"\n",
    "for text in contexts:\n",
    "    background += text + \" \"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending query to OpenAI endpoint: http://10.103.251.104:8040/v1/chat/completions\n",
      "Received response...\n",
      "Response: \n",
      "\n",
      "(' Yes, according to the context provided, Abraham Lincoln was indeed the '\n",
      " 'sixteenth President of the United States.')\n"
     ]
    }
   ],
   "source": [
    "# Send retrieved passages along with question to the model to get the answer\n",
    "prompt = \"Use the following context to answer the question afterwards. Only use information from the context and no prior knowledge.\"\n",
    "model = \"mixtral\"\n",
    "model_temp = 0.0\n",
    "answer_size = 500\n",
    "presence_pen = 0.5\n",
    "repeat_pen = 0.5\n",
    "\n",
    "for question in questions[:1]: \n",
    "    messages = [\n",
    "                    {\"role\": \"user\", \"content\": prompt},\n",
    "                    {\"role\": \"assistant\", \"content\": background},\n",
    "                    {\"role\": \"user\", \"content\": question},\n",
    "                ]\n",
    "    headers = {\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"Authorization\": f\"Bearer N/A \",\n",
    "               }\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": model_temp,\n",
    "        \"max_tokens\": answer_size,\n",
    "        \"presence_penalty\": presence_pen,\n",
    "        \"repeat_penalty\": repeat_pen,\n",
    "    }\n",
    "    endpoint = LLM_URL + \"/chat/completions\"\n",
    "    print(\"Sending query to OpenAI endpoint: \" + endpoint)\n",
    "    report = requests.post(\n",
    "        endpoint, headers=headers, json=data\n",
    "    ).json()\n",
    "    print(\"Received response...\")\n",
    "    if \"choices\" in report:\n",
    "        if (\n",
    "            len(report[\"choices\"]) > 0\n",
    "        ):  # Always take the first choice.\n",
    "            result = report[\"choices\"][0][\"message\"][\"content\"]\n",
    "        else:\n",
    "            result = \"No result generated!\"\n",
    "    else:\n",
    "        result = report\n",
    "    print(\"Response: \\n\")\n",
    "    pprint.pprint(result)\n",
    "\n",
    "\n",
    "# 2. Analyse if answer built upon search results  - FAITHFULNESS\n",
    "def evaluate_faithfulness(contexts, llm_response):\n",
    "    return random.random()\n",
    "\n",
    "faithfulness_score = evaluate_faithfulness(contexts, result)\n",
    "\n",
    "# 3. Analyse if answer is relevant to the question - ANSWER RELEVANCE\n",
    "def evaluate_answer_relevance(question, llm_response):\n",
    "    return random.random()\n",
    "\n",
    "answer_relevance_score = evaluate_answer_relevance(question, result)\n",
    "\n",
    "\n",
    "\n",
    "# 4. Analyse if answer is correct - ANSWER CORRECTNESS\n",
    "\n",
    "def evaluate_correctness(answer,llm_response):\n",
    "    return random.random()\n",
    "\n",
    "correctness_score = evaluate_correctness(answer,response):\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_koenigsi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
