{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to develop rag evaluation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define API ENDPOINTS \n",
    "LLM_URL=\"http://10.103.251.104:8040/v1\"\n",
    "LLM_NAME=\"mixtral\"\n",
    "MARQO_URL=\"http://10.103.251.104:8882\"\n",
    "# Old Marqo endpoint; version 1.5\n",
    "# MARQO_URL=\"http://10.103.251.100:8882\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and Functions \n",
    "import marqo\n",
    "import re\n",
    "import os\n",
    "from langchain.text_splitter import (\n",
    "    CharacterTextSplitter,  # need to install langchain\n",
    "    NLTKTextSplitter,\n",
    "    RecursiveCharacterTextSplitter,\n",
    ")\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "def token_estimate(text):  # OpenAI suggest a token consists of 3/4 words\n",
    "    return len(re.findall(r\"\\w+\", text)) * 4 / 3\n",
    "\n",
    "\n",
    "def get_marqo_client(murl):\n",
    "    # Create a connection with the marqo instance\n",
    "    return marqo.Client(url=murl)\n",
    "\n",
    "\n",
    "def createIndex(mq, indexName, settings):\n",
    "    try:\n",
    "        split_method = settings[\"split_method\"]\n",
    "        distance_metric = settings[\"distance_metric\"]\n",
    "        model = settings[\"model\"]\n",
    "\n",
    "    except:\n",
    "        print(\n",
    "            f\"Settings could not be parsed to create a new index with name: {indexName}\"\n",
    "        )\n",
    "\n",
    "    indexName = indexName.lower()\n",
    "    if indexName in mq.get_indexes():\n",
    "        print(f\"Index already exists: {indexName} \")\n",
    "    else:\n",
    "        index_settings = {\n",
    "                \"model\": model,\n",
    "                \"normalizeEmbeddings\": True,\n",
    "                \"textPreprocessing\": {\n",
    "                    \"splitLength\": 2,\n",
    "                    \"splitOverlap\": 0,\n",
    "                    \"splitMethod\": split_method,\n",
    "                },\n",
    "                \"annParameters\": {\n",
    "                    \"spaceType\": distance_metric,\n",
    "                    \"parameters\": {\"efConstruction\": 512, \"m\": 16},\n",
    "                },\n",
    "        }\n",
    "        try:\n",
    "            mq.create_index(indexName, settings_dict=index_settings)\n",
    "            #mq.create_index(indexName,  model='flax-sentence-embeddings/all_datasets_v4_mpnet-base')\n",
    "            print(\"New index created: \" + indexName)\n",
    "        except:\n",
    "            print(\n",
    "                \"Failed to created new index: \" + indexName + \" - check marqo endpoint!\"\n",
    "            )\n",
    "\n",
    "\n",
    "def deleteIndex(mq, indexName):\n",
    "    # Delete index by indexName\n",
    "    try:\n",
    "        # now remove the marqo index\n",
    "        mq.delete_index(indexName)\n",
    "        # now remove the files -- For now, no need to delete the files locally.\n",
    "        # output_directory = os.path.join(OUTPUT_DIRECTORY, indexName)\n",
    "        # if os.path.exists(output_directory):\n",
    "        #     shutil.rmtree(output_directory)\n",
    "        # else:\n",
    "        #     print(\"No associated file directories found and hence none deleted.\")\n",
    "\n",
    "        print(f\" Sucessfuylly deleted Index: {indexName}\")\n",
    "    except:\n",
    "        print(\"Unable to delete: \" + indexName)\n",
    "\n",
    "\n",
    "def printIndexes(marqoClient):\n",
    "    for index in marqoClient.get_indexes()[\"results\"]:\n",
    "        print(index)\n",
    "\n",
    "\n",
    "def upload_mini_wiki(corpus, chunking_params):\n",
    "    # Upload a mini wiki corpus to the marqo instance\n",
    "    # The corpus is a dictionary with two keys. Passages and id. \n",
    "    # Passage is a list of strings \n",
    "    # Id is a list of ints.\n",
    "    # Open the PDF file\n",
    "   \n",
    "        for passage, iD in zip(corpus[\"passage\"], corpus[\"id\"]):\n",
    "\n",
    "            tokens = token_estimate(passage)\n",
    "            # TODO: Add a check and compare current file by id and timestamp\n",
    "            # If file is already in the index, check if it has been modified\n",
    "            # If the file has been modified, update the file in the index\n",
    "            try:\n",
    "                marqoClient.index(INDEX_NAME).add_documents(\n",
    "                    [\n",
    "                        {\n",
    "                            \"text\": passage,\n",
    "                            \"tokens\": tokens,\n",
    "                            \"id\": iD,\n",
    "                        }\n",
    "                    ],\n",
    "                    # Arguments in tensor_fields will have vectors generated for them. For best recall and performance, minimise the number of arguments in tensor_fields.\n",
    "                    tensor_fields=[\"text\"],\n",
    "                )\n",
    "            except:\n",
    "                print(f\"Ingest error for passage with id: {iD}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New index created: mini_wiki_index\n",
      "{'indexName': 'mini_wiki_index'}\n",
      "{'indexName': 'ait-qm'}\n",
      "{'numberOfDocuments': 5, 'numberOfVectors': 8, 'backend': {'memoryUsedPercentage': None, 'storageUsedPercentage': None}}\n",
      " Sucessfuylly deleted Index: mini_wiki_index\n",
      "{'indexName': 'ait-qm'}\n"
     ]
    }
   ],
   "source": [
    "# Set Index Settings, docs: https://docs.marqo.ai/2.5/API-Reference/Indexes/create_index/\n",
    "\n",
    "# Open marqo with index name, if index not found create new index with the name\n",
    "marqoClient = get_marqo_client(MARQO_URL)\n",
    "INDEX_NAME = \"mini_wiki_index\"\n",
    "index_params = {\n",
    "    \"split_method\": \"sentence\",\n",
    "    \"distance_metric\": \"prenormalized-angular\",\n",
    "    #\"model\": \"hf/all_datasets_v4_MiniLM-L6\",\n",
    "    \"model\" : 'flax-sentence-embeddings/all_datasets_v4_mpnet-base',\n",
    "}\n",
    "\n",
    "chunking_params = {\n",
    "    \"chunk_size\": 1024,\n",
    "    \"chunk_overlap\": 128,\n",
    "    \"chunk_method\": \"recursive\",\n",
    "}\n",
    "\n",
    "# Test createIndex and deleteIndex\n",
    "createIndex(marqoClient, INDEX_NAME, index_params)\n",
    "printIndexes(marqoClient)\n",
    "\n",
    "\n",
    "# Index chunks of data\n",
    "# Get the mini wiki corpus\n",
    "mini_wiki_corpus = load_dataset(\"rag-datasets/mini_wikipedia\", \"text-corpus\")\n",
    "passages = mini_wiki_corpus[\"passages\"][0:5] # Load the first 5 passages\n",
    "upload_mini_wiki(passages, chunking_params)\n",
    "# Check if index contains data\n",
    "print(marqoClient.index(INDEX_NAME).get_stats())\n",
    "deleteIndex(marqoClient, INDEX_NAME)\n",
    "printIndexes(marqoClient)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get question - answer - (passages) dataset\n",
    "\n",
    "# Send Questions to index to retrieve data from vector db \n",
    "\n",
    "# 1. Analyse Search Results - CONTEXT RELEVANCE\n",
    "\n",
    "# Send retrieved passages along with queestion to the model to get the answer\n",
    "\n",
    "# 2. Analyse if answer built upon search results  - FAITHFULNESS\n",
    "\n",
    "# 3. Analyse if answer is relevant to the question - ANSWER RELEVANCE\n",
    "\n",
    "# 4. Analyse if answer is correct - ANSWER CORRECTNESS \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_koenigsi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
